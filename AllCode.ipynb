{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dlike230/CIS520FinalProject/blob/master/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ktrain in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: torch in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 3)) (3.4.5)\n",
      "Requirement already satisfied: numpy>=1.17.4 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 4)) (1.17.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 5)) (0.21.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 7)) (0.25.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 8)) (0.0.1)\n",
      "Requirement already satisfied: tensorflow==1.14 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: keras-bert in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (0.80.0)\n",
      "Requirement already satisfied: langdetect in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: jieba in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (0.39)\n",
      "Requirement already satisfied: cchardet in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: bokeh in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: eli5>=0.10.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (0.10.1)\n",
      "Requirement already satisfied: seqeval in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (0.0.12)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (0.1.22)\n",
      "Requirement already satisfied: networkx==2.3 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (2.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: keras==2.2.4 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (2.2.4)\n",
      "Requirement already satisfied: requests in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from ktrain->-r requirements.txt (line 1)) (2.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\owen\\appdata\\roaming\\python\\python36\\site-packages (from nltk->-r requirements.txt (line 3)) (1.13.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (2.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2018.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bs4->-r requirements.txt (line 8)) (4.7.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (0.33.6)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (0.2.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (1.25.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (0.1.8)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow==1.14->-r requirements.txt (line 9)) (0.8.0)\n",
      "Requirement already satisfied: keras-transformer>=0.30.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-bert->ktrain->-r requirements.txt (line 1)) (0.31.0)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (19.2)\n",
      "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (2.10.3)\n",
      "Requirement already satisfied: tornado>=4.3 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (5.2)\n",
      "Requirement already satisfied: pillow>=4.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from bokeh->ktrain->-r requirements.txt (line 1)) (6.2.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from eli5>=0.10.0->ktrain->-r requirements.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: attrs>16.0.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from eli5>=0.10.0->ktrain->-r requirements.txt (line 1)) (19.3.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from eli5>=0.10.0->ktrain->-r requirements.txt (line 1)) (0.8.6)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from networkx==2.3->ktrain->-r requirements.txt (line 1)) (4.4.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras==2.2.4->ktrain->-r requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->ktrain->-r requirements.txt (line 1)) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->ktrain->-r requirements.txt (line 1)) (2018.8.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->ktrain->-r requirements.txt (line 1)) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->ktrain->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 6)) (42.0.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 8)) (1.9.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->-r requirements.txt (line 9)) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->-r requirements.txt (line 9)) (0.16.0)\n",
      "Requirement already satisfied: keras-embed-sim>=0.7.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-transformer>=0.30.0->keras-bert->ktrain->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: keras-layer-normalization>=0.12.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-transformer>=0.30.0->keras-bert->ktrain->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward>=0.5.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-transformer>=0.30.0->keras-bert->ktrain->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: keras-pos-embd>=0.10.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-transformer>=0.30.0->keras-bert->ktrain->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: keras-multi-head>=0.22.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-transformer>=0.30.0->keras-bert->ktrain->-r requirements.txt (line 1)) (0.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from Jinja2>=2.7->bokeh->ktrain->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: keras-self-attention==0.41.0 in c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from keras-multi-head>=0.22.0->keras-transformer>=0.30.0->keras-bert->ktrain->-r requirements.txt (line 1)) (0.41.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def graph_reconstruction(X, delta = 10, max_components = 1000, print_progress = False):\n",
    "\n",
    "\tfrobenii = [np.linalg.norm(X.toarray())]\n",
    "\trnge = [i for i in range(delta, max_components + delta, delta)]\n",
    "\n",
    "\tfor i in rnge:\n",
    "\t\tdim_reducer = TruncatedSVD(n_components=i)\n",
    "\t\tshrunk = dim_reducer.fit_transform(X)\n",
    "\t\tX_reconst = dim_reducer.inverse_transform(shrunk)\n",
    "\t\tfrobenii.append(np.linalg.norm(X - X_reconst))\n",
    "\t\tif (print_progress):\n",
    "\t\t\tprint(\"{}% complete\".format(100 * i / max_components))\n",
    "\n",
    "\tcomponents = [0]\n",
    "\tcomponents.extend(rnge)\n",
    "\n",
    "\tplt.plot(components, frobenii)\n",
    "\tplt.show()\n",
    "\treturn components, frobenii\n",
    "\n",
    "\n",
    "def graph_eigenvalues(X):\n",
    "\tX = X.toarray()\n",
    "\t_, s, _ = np.linalg.svd(X)\n",
    "\tvalues = s\n",
    "\tplt.plot(values)\n",
    "\tplt.show()\n",
    "\treturn values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def get_df() -> DataFrame:\n",
    "    return pd.read_csv(\"./data/Reviews.csv\", sep=',', quotechar='\"')\n",
    "\n",
    "\n",
    "def extract_text(df) -> List[str]:\n",
    "    return [Soup(text, features=\"html.parser\").get_text() for text in df[\"Text\"]]\n",
    "\n",
    "\n",
    "def balance_dataset(df, label_col, sample_size):\n",
    "    part1: DataFrame = df[df[label_col] == 1].sample(n=sample_size // 2)\n",
    "    part2: DataFrame = df[df[label_col] == 0].sample(n=sample_size // 2)\n",
    "    df = part1.append(part2)\n",
    "    df = df.sample(frac=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_data(sample_size=10000):\n",
    "    raw_df = get_df()\n",
    "    if sample_size is not None:\n",
    "        df = raw_df.sample(n=sample_size)\n",
    "    else:\n",
    "        df = raw_df\n",
    "    texts = extract_text(df)\n",
    "    return texts, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class Vectorizer:\n",
    "\n",
    "    def __init__(self, pca=True, base_model=TfidfVectorizer(lowercase=True), make_array=False):\n",
    "        self.base_model = base_model\n",
    "        self.dimensionality_reducer = None\n",
    "        self.pca = pca\n",
    "        self.make_array = make_array\n",
    "\n",
    "    def fit_transform(self, reviews: List[str]):\n",
    "        X_train = self.base_model.fit_transform(reviews)\n",
    "        if self.pca:\n",
    "            self.dimensionality_reducer = TruncatedSVD(n_components=1000)\n",
    "            X_train = self.dimensionality_reducer.fit_transform(X_train)\n",
    "        elif self.make_array:\n",
    "            X_train = X_train.toarray()\n",
    "        return X_train\n",
    "\n",
    "    def transform(self, comments: List[str]):\n",
    "        if self.pca:\n",
    "            comments = self.dimensionality_reducer.transform(self.base_model.transform(comments))\n",
    "        else:\n",
    "            comments = self.base_model.transform(comments)\n",
    "            if self.make_array:\n",
    "                comments = comments.toarray()\n",
    "        return comments\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, vectorizer=Vectorizer(pca=True), model=SVC()):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, reviews_train: List[str], y_train):\n",
    "        X_train = self.vectorizer.fit_transform(reviews_train) if self.vectorizer is not None else reviews_train\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, reviews_test: List[str]):\n",
    "        X_test = self.vectorizer.transform(reviews_test) if self.vectorizer is not None else reviews_test\n",
    "        return np.round(np.array(self.model.predict(X_test)))\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {'model' : self.model, 'vectorizer' : self.vectorizer}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, auc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, label_col, p_train, should_subsample=True, sample_size=20000):\n",
    "        df = get_df()\n",
    "        df[label_col] = df[label_col].apply(self.label_func)\n",
    "        if should_subsample:\n",
    "            df = balance_dataset(df, label_col, sample_size)\n",
    "        else:\n",
    "            df = df.sample(n=sample_size)\n",
    "        self.text_data = extract_text(df)\n",
    "        self.labels = df[label_col]\n",
    "        self.metrics = [accuracy_score, lambda a, b: fbeta_score(a, b, 1)]\n",
    "        self.p_train = p_train\n",
    "\n",
    "    def label_func(self, item):\n",
    "        \"\"\"\n",
    "        Takes an item from the label column in the dataset and generates a numerical label to input into the model\n",
    "        :param item:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        raise Exception(\"Not implemented\")\n",
    "\n",
    "    def make_model(self):\n",
    "        raise Exception(\"Not implemented\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        n_train = int(self.p_train * len(self.text_data))\n",
    "        reviews_train = self.text_data[:n_train]\n",
    "        reviews_test = self.text_data[n_train:]\n",
    "        labels_train = self.labels[:n_train]\n",
    "        labels_test = self.labels[n_train:]\n",
    "        model = self.make_model()\n",
    "        if type(model) == list:\n",
    "            for model_name, individual_model in model:\n",
    "                print(\"MODEL %s\" % model_name)\n",
    "                individual_model.fit(reviews_train, np.array(labels_train))\n",
    "                predictions = np.round(individual_model.predict(reviews_test))\n",
    "                for i, score in enumerate(self.metrics):\n",
    "                    print(\"Metric\", str(i) + \":\", score(predictions, np.array(labels_test)))\n",
    "        else:\n",
    "            model.fit(reviews_train, np.array(labels_train))\n",
    "            predictions = np.round(model.predict(reviews_test))\n",
    "            for i, score in enumerate(self.metrics):\n",
    "                print(\"Metric\", str(i) + \":\", score(predictions, np.array(labels_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumb baseline model, predicts majority class of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dumb:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, train_strings, y_train):\n",
    "        c1 = 0\n",
    "        for y in y_train:\n",
    "            if y == 0:\n",
    "                c1 += 1\n",
    "        c2 = len(y_train) - c1\n",
    "        self.model = 0 if c1 > c2 else 1\n",
    "\n",
    "    def predict(self, reviews_test):\n",
    "        return [self.model] * len(reviews_test)\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {'model' : self.model}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "class BERT:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.learner = None\n",
    "        self.predictor = None\n",
    "\n",
    "    def fit(self, train_strings, y_train):\n",
    "        tf.random.set_random_seed(0)\n",
    "        (x_train, y_train), (x_test, y_test), preproc = \\\n",
    "            text.texts_from_array(train_strings, y_train, class_names=[\"low\", \"high\"], preprocess_mode=\"bert\", maxlen=300, lang=\"en\")\n",
    "        self.model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n",
    "        learner = ktrain.get_learner(self.model, train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=12)\n",
    "        self.learner = learner\n",
    "        learner.fit_onecycle(1e-5,1)\n",
    "        learner.plot('loss')\n",
    "        plt.show()\n",
    "        self.predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "\n",
    "    def find_lr(self):\n",
    "        self.learner.lr_find(max_epochs=1, show_plot=True)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    def predict(self, reviews_test):\n",
    "        return [(0 if i == 'low' else 1) for i in self.predictor.predict(reviews_test)]\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {'model':self.model, 'learner':self.learner, 'predictor':self.predictor}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from text_encoders.CharacterEncoder import CharacterRNNEncoder\n",
    "from text_encoders.WordEncoder import WordEncoder\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "class RNN:\n",
    "\n",
    "    def __init__(self, encode_words=True):\n",
    "        if encode_words:\n",
    "            self.encoder = WordEncoder()\n",
    "        else:\n",
    "            self.encoder = CharacterRNNEncoder()\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, train_strings, y_train):\n",
    "        val_size = round(len(train_strings) * 0.5)\n",
    "        train_strings, val_strings = train_strings[:val_size], train_strings[val_size:]\n",
    "        X_train = self.encoder.fit_transform(train_strings)\n",
    "        y_train, y_val = y_train[:val_size], y_train[val_size:]\n",
    "        X_val = self.encoder.transform(val_strings)\n",
    "        vocab_size = self.encoder.vocab_size\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(vocab_size + 2, 64),\n",
    "            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
    "            tf.keras.layers.Dense(1024, activation='relu'),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                           metrics=[\n",
    "                               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                               tf.keras.metrics.Precision(name='precision'),\n",
    "                               tf.keras.metrics.Recall(name='recall'),\n",
    "                               tf.keras.metrics.AUC(name='auc'),\n",
    "                           ])\n",
    "        self.model.fit(x=X_train, y=np.array([1 if item else 0 for item in y_train]), epochs=5,\n",
    "                       validation_data=(X_val, np.array([1 if item else 0 for item in y_val])), validation_steps=10)\n",
    "\n",
    "    def predict(self, reviews_test):\n",
    "        return [prediction[0] for prediction in self.model.predict(self.encoder.transform(reviews_test))]\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {'model':self.model, 'encoder':self.encoder}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding model (based on Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class WordEmbeddingModel:\n",
    "\n",
    "    def fit(self, vectors, train_labels):\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(512, input_dim=vectors.shape[1], activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                           metrics=[\n",
    "                               tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                               tf.keras.metrics.Precision(name='precision'),\n",
    "                               tf.keras.metrics.Recall(name='recall'),\n",
    "                               tf.keras.metrics.AUC(name='auc'),\n",
    "                           ])\n",
    "        self.model.fit(x=vectors, y=train_labels, epochs=2)\n",
    "\n",
    "    def predict(self, vectors):\n",
    "        return self.model.predict(vectors)\n",
    "\n",
    "    def get_params(self, deep = True):\n",
    "        return {'model':self.model}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk pipeline for running multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BulkPipeline(Pipeline):\n",
    "\n",
    "    def __init__(self, models, names):\n",
    "        super().__init__(\"Score\", 0.5)\n",
    "        self.models = models\n",
    "        self.names = names\n",
    "\n",
    "    def make_model(self):\n",
    "        return list(zip(self.names, self.models))\n",
    "\n",
    "    def label_func(self, item):\n",
    "        return 1 if item > 3 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate and evaluate the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL Dumb baseline\n",
      "Metric 0: 0.4989\n",
      "Metric 1: 0.0\n",
      "MODEL Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric 0: 0.6459\n",
      "Metric 1: 0.6918994170364571\n",
      "MODEL Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric 0: 0.8252\n",
      "Metric 1: 0.8241094787683638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "baseline_models = [Dumb(), Model(model=GaussianNB(), vectorizer=Vectorizer(make_array=True)), \n",
    "                   Model(model=LogisticRegression(), vectorizer=Vectorizer())]\n",
    "baseline_names = [\"Dumb baseline\", \"Naive Bayes\", \"Logistic Regression\"]\n",
    "\n",
    "pipeline = BulkPipeline(baseline_models, baseline_names)\n",
    "pipeline.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dumb baseline and Naive Bayes classifier are both pretty bad, but the logistic regression works pretty well. Now,\n",
    "we will experiment with some other models and look closer into logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owen\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = Vectorizer(pca=True)\n",
    "\n",
    "experimental_models = [Model(model=SVC(), vectorizer=vect), Model(model=AdaBoostClassifier, vectorizer=vect), \n",
    "                      Model(model=GradientBoostingClassifier(), vectorizer = vect), \n",
    "                       Model(model = RandomForestClassifier(), vectorizer = vect), RNN(encode_words=True),\n",
    "                      Model(model=WordEmbeddingModel(), vectorizer=Vectorizer(pca=False, base_model=CountVectorizer())), \n",
    "                      BERT()]\n",
    "experimental_models_names = ['SVM', 'AdaBoost Classifier', 'Gradient Tree Boosting Classifier', 'Random Forest',\n",
    "                             'RNN', 'Unigram Neural Net', 'BERT']\n",
    "\n",
    "\n",
    "pipeline = BulkPipeline(experimental_models, experimental_models_names)\n",
    "pipeline.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the models are promising and some are garbage. However, what really stands out is BERT. BERT is better than anything else we've seen by far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look closer into logistic regression and tune hyperparameters. Here, we use the elastic net penalty and iterate over the\n",
    "hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL Logistic: pca: 0, C: 0.25, l1_ratio: 0\n",
      "Metric 0: 0.8241\n",
      "Metric 1: 0.821294320837143\n",
      "MODEL Logistic: pca: 0, C: 0.25, l1_ratio: 0.25\n",
      "Metric 0: 0.8084\n",
      "Metric 1: 0.8056795131845842\n",
      "MODEL Logistic: pca: 0, C: 0.25, l1_ratio: 0.5\n",
      "Metric 0: 0.797\n",
      "Metric 1: 0.793615290768605\n",
      "MODEL Logistic: pca: 0, C: 0.25, l1_ratio: 0.75\n",
      "Metric 0: 0.7882\n",
      "Metric 1: 0.7841418671015083\n",
      "MODEL Logistic: pca: 0, C: 0.25, l1_ratio: 1\n",
      "Metric 0: 0.784\n",
      "Metric 1: 0.7788697788697788\n",
      "MODEL Logistic: pca: 0, C: 0.5, l1_ratio: 0\n",
      "Metric 0: 0.8343\n",
      "Metric 1: 0.8310045894951555\n",
      "MODEL Logistic: pca: 0, C: 0.5, l1_ratio: 0.25\n",
      "Metric 0: 0.8266\n",
      "Metric 1: 0.8230973270761069\n",
      "MODEL Logistic: pca: 0, C: 0.5, l1_ratio: 0.5\n",
      "Metric 0: 0.8193\n",
      "Metric 1: 0.815781425221735\n",
      "MODEL Logistic: pca: 0, C: 0.5, l1_ratio: 0.75\n",
      "Metric 0: 0.8152\n",
      "Metric 1: 0.8114285714285714\n",
      "MODEL Logistic: pca: 0, C: 0.5, l1_ratio: 1\n",
      "Metric 0: 0.8107\n",
      "Metric 1: 0.8061840892802293\n",
      "MODEL Logistic: pca: 0, C: 1, l1_ratio: 0\n",
      "Metric 0: 0.8408\n",
      "Metric 1: 0.8379808670873194\n",
      "MODEL Logistic: pca: 0, C: 1, l1_ratio: 0.25\n",
      "Metric 0: 0.8398\n",
      "Metric 1: 0.8369299674267102\n",
      "MODEL Logistic: pca: 0, C: 1, l1_ratio: 0.5\n",
      "Metric 0: 0.8353\n",
      "Metric 1: 0.8320587335576629\n",
      "MODEL Logistic: pca: 0, C: 1, l1_ratio: 0.75\n",
      "Metric 0: 0.8326\n",
      "Metric 1: 0.8298780487804878\n",
      "MODEL Logistic: pca: 0, C: 1, l1_ratio: 1\n",
      "Metric 0: 0.8283\n",
      "Metric 1: 0.8255258611929682\n",
      "MODEL Logistic: pca: 0, C: 1.5, l1_ratio: 0\n",
      "Metric 0: 0.8438\n",
      "Metric 1: 0.8412601626016261\n",
      "MODEL Logistic: pca: 0, C: 1.5, l1_ratio: 0.25\n",
      "Metric 0: 0.8429\n",
      "Metric 1: 0.8405561757840252\n",
      "MODEL Logistic: pca: 0, C: 1.5, l1_ratio: 0.5\n",
      "Metric 0: 0.8415\n",
      "Metric 1: 0.8389391322020121\n",
      "MODEL Logistic: pca: 0, C: 1.5, l1_ratio: 0.75\n",
      "Metric 0: 0.8383\n",
      "Metric 1: 0.8359208523592084\n",
      "MODEL Logistic: pca: 0, C: 1.5, l1_ratio: 1\n",
      "Metric 0: 0.8354\n",
      "Metric 1: 0.83329957464047\n",
      "MODEL Logistic: pca: 0, C: 2, l1_ratio: 0\n",
      "Metric 0: 0.8442\n",
      "Metric 1: 0.8420839245894992\n",
      "MODEL Logistic: pca: 0, C: 2, l1_ratio: 0.25\n",
      "Metric 0: 0.8446\n",
      "Metric 1: 0.8422655298416566\n",
      "MODEL Logistic: pca: 0, C: 2, l1_ratio: 0.5\n",
      "Metric 0: 0.8431\n",
      "Metric 1: 0.8408560705953951\n",
      "MODEL Logistic: pca: 0, C: 2, l1_ratio: 0.75\n",
      "Metric 0: 0.8403\n",
      "Metric 1: 0.8378844787331234\n",
      "MODEL Logistic: pca: 0, C: 2, l1_ratio: 1\n",
      "Metric 0: 0.8371\n",
      "Metric 1: 0.8352048558421852\n",
      "MODEL Logistic: pca: 0, C: 4, l1_ratio: 0\n",
      "Metric 0: 0.8435\n",
      "Metric 1: 0.8416793120890237\n",
      "MODEL Logistic: pca: 0, C: 4, l1_ratio: 0.25\n",
      "Metric 0: 0.8406\n",
      "Metric 1: 0.8387618854946388\n",
      "MODEL Logistic: pca: 0, C: 4, l1_ratio: 0.5\n",
      "Metric 0: 0.8408\n",
      "Metric 1: 0.8390618681763041\n",
      "MODEL Logistic: pca: 0, C: 4, l1_ratio: 0.75\n",
      "Metric 0: 0.8414\n",
      "Metric 1: 0.8395711106615416\n",
      "MODEL Logistic: pca: 0, C: 4, l1_ratio: 1\n",
      "Metric 0: 0.8364\n",
      "Metric 1: 0.8352135374697823\n",
      "MODEL Logistic: pca: 0, C: 8, l1_ratio: 0\n",
      "Metric 0: 0.8414\n",
      "Metric 1: 0.8398950131233597\n",
      "MODEL Logistic: pca: 0, C: 8, l1_ratio: 0.25\n",
      "Metric 0: 0.8418\n",
      "Metric 1: 0.8401051142106326\n",
      "MODEL Logistic: pca: 0, C: 8, l1_ratio: 0.5\n",
      "Metric 0: 0.8399\n",
      "Metric 1: 0.8383970929645705\n",
      "MODEL Logistic: pca: 0, C: 8, l1_ratio: 0.75\n",
      "Metric 0: 0.8357\n",
      "Metric 1: 0.8344584382871536\n",
      "MODEL Logistic: pca: 0, C: 8, l1_ratio: 1\n",
      "Metric 0: 0.8306\n",
      "Metric 1: 0.8293714746172443\n",
      "MODEL Logistic: pca: 0, C: 16, l1_ratio: 0\n",
      "Metric 0: 0.836\n",
      "Metric 1: 0.8347773524078178\n",
      "MODEL Logistic: pca: 0, C: 16, l1_ratio: 0.25\n",
      "Metric 0: 0.8348\n",
      "Metric 1: 0.8337359098228663\n",
      "MODEL Logistic: pca: 0, C: 16, l1_ratio: 0.5\n",
      "Metric 0: 0.8333\n",
      "Metric 1: 0.8321079665625943\n",
      "MODEL Logistic: pca: 0, C: 16, l1_ratio: 0.75\n",
      "Metric 0: 0.8312\n",
      "Metric 1: 0.8302493966210781\n",
      "MODEL Logistic: pca: 0, C: 16, l1_ratio: 1\n",
      "Metric 0: 0.8262\n",
      "Metric 1: 0.8251157174481787\n",
      "MODEL Logistic: pca: 0, C: 32, l1_ratio: 0\n",
      "Metric 0: 0.8305\n",
      "Metric 1: 0.8296653602653\n",
      "MODEL Logistic: pca: 0, C: 32, l1_ratio: 0.25\n",
      "Metric 0: 0.8293\n",
      "Metric 1: 0.8282868926667336\n",
      "MODEL Logistic: pca: 0, C: 32, l1_ratio: 0.5\n",
      "Metric 0: 0.8276\n",
      "Metric 1: 0.8265942466304567\n",
      "MODEL Logistic: pca: 0, C: 32, l1_ratio: 0.75\n",
      "Metric 0: 0.8239\n",
      "Metric 1: 0.823316945921541\n",
      "MODEL Logistic: pca: 0, C: 32, l1_ratio: 1\n",
      "Metric 0: 0.8223\n",
      "Metric 1: 0.8214967353088899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_zipped = [(\"Logistic: pca: %s, C: %s, l1_ratio: %s\" % (pca, val, rat), Model(model=LogisticRegression(C=val, penalty=\n",
    "                                                                'elasticnet', solver='saga', l1_ratio=rat),\n",
    "                                                                vectorizer=Vectorizer(pca=pca == 1))) for pca in\n",
    "                range(1) for val in [0.25, 0.5, 1, 1.5, 2, 4, 8, 16, 32] for rat in [0, .25, .5, .75, 1]]\n",
    "\n",
    "log_models = []\n",
    "log_names = []\n",
    "\n",
    "for n,l in log_zipped:\n",
    "    log_names.append(n)\n",
    "    log_models.append(l)\n",
    "\n",
    "pipeline = BulkPipeline(log_models, log_names)\n",
    "pipeline.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hyperparameter search reveals that a C value of 8 and an l1_ratio of .25 are ideal, yielding the highest metrics:\n",
    "Metric 0: 0.8418\n",
    "Metric 1: 0.8401051142106326\n",
    "Now, we will see if utilizing pca results in improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL Log Reg with PCA\n",
      "Metric 0: 0.8309\n",
      "Metric 1: 0.8276424421567629\n"
     ]
    }
   ],
   "source": [
    "pipeline = BulkPipeline([Model(model=LogisticRegression(C=8, penalty='elasticnet', solver='saga', l1_ratio=0.25),\n",
    "                        vectorizer=Vectorizer(pca=True))], ['Log Reg with PCA'])\n",
    "pipeline.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try auto-sklearn. Note: this can only be run on a UNIX system, so the following two blocks are not shown executed, since we are using Windows machines. We executed this code in a separate Linux environment, and reported the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "pipeline = BulkPipeline([Model(model=AutoSklearnClassifier(), vectorizer=Vectorizer(pca=True))], ['auto sklearn'])\n",
    "pipeline.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw these results:\n",
    "Metric 0: 0.8378\n",
    "Metric 1: 0.83526\n",
    "\n",
    "Not bad, it beats the baseline logistic regression. However, with hyperparameter tuning, we beat it. So, we will not move forward with auto-sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our results indicate that BERT and Logistic Regression are our best two models. BERT is significantly better than \n",
    "Logistic Regression, but Logistic Regression beats everything else."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
